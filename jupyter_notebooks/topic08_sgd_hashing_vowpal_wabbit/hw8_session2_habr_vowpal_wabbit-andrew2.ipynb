{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 2\n",
    "</center>\n",
    "Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Домашнее задание № 8\n",
    "## <center> Vowpal Wabbit в задаче прогнозирования популярности статьи на хабре"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании надо побить бенчмарк в [соревновании](https://www.kaggle.com/c/habr-num-bookmarks) на Kaggle Inclass. Как это делать – ограничений нет (кроме, конечно, ручной разметки), прочитать правила можно [тут](https://www.kaggle.com/c/habr-num-bookmarks/rules). Ниже описаны инструкции, как это сделать с Vowpal Wabbit.\n",
    "\n",
    "Дедлайн: 31 октября 23:59 UTC +3. Решение надо будет загрузить по [ссылке](https://www.dropbox.com/request/g5WOPrxwvcYwADZCuoY7). В этом соревновании нет задачи победить. Цель – побить бенчмарк и продвинуться в [соревновании](https://mlcourse.arktur.io) по прогнозу популярности статьи на Medium. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на одну из строчек в JSON-файле: считаем ее с помощью библиотеки json. Эта строчка соответствует [7-ой статье](https://habrahabr.ru/post/7/) на Хабре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!head -2 ../../data/medium/train.json > ../../data/medium/train1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../../data/medium/train1.json') as inp_json:\n",
    "    first_json = json.load(inp_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', '_timestamp', 'author', 'content', 'domain', 'flags', 'flow', 'hubs', 'link_tags', 'meta_tags', 'polling', 'post_id', 'published', 'tags', 'title', 'url'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим 16 полей, перечислим некоторые из них:\n",
    "- _id, url - URL статьи\n",
    "- published – время публикации статьи\n",
    "- domain – сайт (например, habrahahbr.ru или geektimes.ru)\n",
    "- title – название статьи\n",
    "- content – текст статьи\n",
    "- hubs - перечисление хабов, к которым относится статья\n",
    "- tags – теги статьи\n",
    "- author – автор статьи, его ник и ссылка на профиль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://habrahabr.ru/post/7/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1493192186.0903192"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['_timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://habrahabr.ru/post/7/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'habrahabr.ru'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$date': '2006-07-15T01:48:00.000Z'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['published']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Самопроизвольное разлогинивание'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'У меня такое ощущение, что logout время от времени происходит самопроизвольно, несмотря на то, что чекбокс про логине включен.<br>\\r\\n<br>\\r\\nВозможно, это происходит при смене IP-адреса, но я не уверен.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_json['polling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['post_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['flags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'hub/habr',\n",
       "  'title': 'Хабрахабр',\n",
       "  'url': 'https://habrahabr.ru/hub/habr/'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['hubs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_json['flow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['логин', 'login']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Павел Титов',\n",
       " 'nickname': '@ptitov',\n",
       " 'url': 'https://habrahabr.ru/users/ptitov'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alternate': 'https://habrahabr.ru/rss/post/7/',\n",
       " 'apple-touch-icon-precomposed': '/images/favicons/apple-touch-icon-152x152.png',\n",
       " 'canonical': 'https://habrahabr.ru/post/7/',\n",
       " 'icon': '/images/favicons/favicon-16x16.png',\n",
       " 'image_src': 'https://habrahabr.ru/i/habralogo.jpg',\n",
       " 'stylesheet': 'https://habracdn.net/habr/styles/1493134745/_build/global_main.css'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['link_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'al:android:app_name': 'Habrahabr',\n",
       " 'al:android:package': 'ru.habrahabr',\n",
       " 'al:android:url': 'habrahabr://post/7',\n",
       " 'al:windows_phone:app_id': '460a6bd6-8955-470f-935e-9ea1726a6060',\n",
       " 'al:windows_phone:app_name': 'Habrahabr',\n",
       " 'al:windows_phone:url': 'habrahabr://post/7',\n",
       " 'apple-mobile-web-app-title': 'Хабрахабр',\n",
       " 'application-name': 'Хабрахабр',\n",
       " 'description': 'У меня такое ощущение, что logout время от времени происходит самопроизвольно, несмотря на то, что чекбокс про логине включен.\\r\\n\\r\\nВозможно, это происходит при смене IP-адреса, но я не уверен.',\n",
       " 'fb:app_id': '444736788986613',\n",
       " 'keywords': 'логин, login',\n",
       " 'msapplication-TileColor': '#FFFFFF',\n",
       " 'msapplication-TileImage': 'mstile-144x144.png',\n",
       " 'og:description': 'У меня такое ощущение, что logout время от времени происходит самопроизвольно, несмотря на то, что чекбокс про логине включен.  Возможно, это происходит при...',\n",
       " 'og:image': 'https://habrahabr.ru/i/habralogo.jpg',\n",
       " 'og:title': 'Самопроизвольное разлогинивание',\n",
       " 'og:type': 'article',\n",
       " 'og:url': 'https://habrahabr.ru/post/7/',\n",
       " 'pocket-site-verification': 'ed24b2b9721edf0a282c5b4a3232c4',\n",
       " 'referrer': 'unsafe-url',\n",
       " 'robots': 'noindex',\n",
       " 'twitter:card': 'summary',\n",
       " 'twitter:site': '@habrahabr',\n",
       " 'viewport': 'width=1024',\n",
       " 'yandex-verification': '67d46b975fa41645'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['meta_tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим ответы на обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_target = pd.read_csv('../../data/medium/train_target.csv',\n",
    "                          index_col='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://habrahabr.ru/post/7/</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/11/</th>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/112/</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/1127/</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/12664/</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    target\n",
       "url                                       \n",
       "https://habrahabr.ru/post/7/      0.693147\n",
       "https://geektimes.ru/post/11/     1.098612\n",
       "https://geektimes.ru/post/112/    0.000000\n",
       "https://geektimes.ru/post/1127/   0.000000\n",
       "https://geektimes.ru/post/12664/  0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируйте обучающую выборку для Vowpal Wabbit, выберите признаки title, tags, domain, flow, author, и hubs из JSON-файла.\n",
    "От самого текста для начала просто возьмем его длину: постройте признак content_len – длина текста в миллионах символов.\n",
    "Также постройте признаки: час и месяц публикации статьи. Еще, конечно же, возьмите ответы на обучающей выборке из `train_target`. Ниже пример того, как могут выглядеть первые две строки нового файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931470000000001 |title Самопроизвольное разлогинивание |tags логин login |domain habrahabr.ru |flow None |author @ptitov |hubs Хабрахабр |num content_len:0.0 month:7 hour:1\r\n",
      "1.0986120000000001 |title Stand-along cообщества против сообществ в рамках социальных сетей |tags сообщества интернет-сообщество социальные сети нишевой бренд |domain geektimes.ru |flow None |author @AlexBruce |hubs Чёрная дыра |num content_len:0.0 month:7 hour:14\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 ../../data/habr_train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16cc868456947fca178e6578373da17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import datetime\n",
    "\n",
    "with open('../../data/medium/train.json') as inp_json, \\\n",
    "    open('../../data/medium/habr_train_full.vw', 'w') as out_train:\n",
    "    \n",
    "    for line in tqdm_notebook(inp_json):\n",
    "        data_json = json.loads(line)\n",
    "        target = train_target.loc[data_json['_id']]['target']\n",
    "        datetime_obj = datetime.datetime.strptime(data_json['published']['$date'], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        title = str(data_json['title']).replace(\":\",\"\").replace(\"|\",\"\")\n",
    "        new_line = str(target) + \\\n",
    "                   ' |title ' + title + \\\n",
    "                   ' |tags ' + ' '.join(data_json['tags']).replace(\":\",\"\").replace(\"|\",\"\") + \\\n",
    "                   ' |domain ' + str(data_json['domain']) + \\\n",
    "                   ' |flow ' + str(data_json['domain']) + \\\n",
    "                   ' |author ' + str(data_json['author']['nickname']) + \\\n",
    "                   ' |hubs ' + ' '.join(map(lambda x: x['title'], data_json['hubs'])).replace(\":\",\"\").replace(\"|\",\"\") + \\\n",
    "                   ' |num content_len:' + str(len(data_json['content']) / 1000) + \\\n",
    "                   ' months_trend:' + str(round((datetime_obj.year * 12 + datetime_obj.month)/2000, 3)) + \\\n",
    "                   ' month_sin:' + str(round(math.sin(datetime_obj.month * math.pi / 6), 3)) + \\\n",
    "                   ' month_cos:' + str(round(math.cos(datetime_obj.month * math.pi / 6), 3)) + \\\n",
    "                   ' hour_sin:' + str(round(math.sin(datetime_obj.hour * math.pi / 12), 3)) + \\\n",
    "                   ' hour_cos:' + str(round(math.cos(datetime_obj.hour * math.pi / 12), 3)) + '\\n'\n",
    "        out_train.write(new_line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделайте все то же с тестовой выборкой, вместо ответов подсовывая что угодно, например, единицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f637d902a7a14c458e01fd28d2a36e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/medium/test.json') as inp_json, \\\n",
    "open('../../data/medium/habr_test.vw', 'w') as out_vw:\n",
    "    for line in tqdm_notebook(inp_json):\n",
    "        data_json = json.loads(line)\n",
    "        target = 1\n",
    "        title = str(data_json['title']).replace(\":\",\"\").replace(\"|\",\"\")\n",
    "        datetime_obj = datetime.datetime.strptime(data_json['published']['$date'], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        #Плюс для тренда общее число месяцев от рождества Христова/2000\n",
    "        \n",
    "        new_line = str(target) + \\\n",
    "                   ' |title ' + title + \\\n",
    "                   ' |tags ' + ' '.join(data_json['tags']).replace(\":\",\"\").replace(\"|\",\"\") + \\\n",
    "                   ' |domain ' + str(data_json['domain']) + \\\n",
    "                   ' |flow ' + str(data_json['domain']) + \\\n",
    "                   ' |author ' + str(data_json['author']['nickname']) + \\\n",
    "                   ' |hubs ' + ' '.join(map(lambda x: x['title'], data_json['hubs'])).replace(\":\",\"\").replace(\"|\",\"\") + \\\n",
    "                   ' |num content_len:' + str(len(data_json['content'])/1e6) + \\\n",
    "                   ' months_trend:' + str(round((datetime_obj.year * 12 + datetime_obj.month)/2000, 3)) + \\\n",
    "                   ' month_sin:' + str(round(math.sin(datetime_obj.month * math.pi / 6), 3)) + \\\n",
    "                   ' month_cos:' + str(round(math.cos(datetime_obj.month * math.pi / 6), 3)) + \\\n",
    "                   ' hour_sin:' + str(round(math.sin(datetime_obj.hour * math.pi / 12), 3)) + \\\n",
    "                   ' hour_cos:' + str(round(math.cos(datetime_obj.hour * math.pi / 12), 3)) + '\\n'     \n",
    "        out_vw.write(new_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 |title День Пи! |tags Пи Pi |domain geektimes.ru |flow None |author @Timursan |hubs Чёрная дыра |num content_len:0.0 month:3 hour:3\r\n",
      "1 |title Скрипт для разбиения образов музыкальных CD на треки и конвертации в формат FLAC |tags bash lossless |domain geektimes.ru |flow None |author @da3mon |hubs Чёрная дыра |num content_len:0.01 month:3 hour:0\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 ../../data/habr_test.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор того, как валидировать модель, остается за Вами. Проще всего, конечно, сделать отложенную выборку. Бенчмарк, который Вы видите в соревновании (**vw_baseline.csv**) и который надо побить, получен с Vowpal Wabbit, 3 проходами по выборке (не забываем удалять кэш), биграммами и настроенными гиперпараметрами `bits`, `learning_rate` и `power_t`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate train to train and holdout for score estimation\n",
    "train_fraction = 0.7\n",
    "\n",
    "with open('../../data/medium/habr_train_full.vw') as train_file, \\\n",
    "    open('../../data/medium/habr_train.vw', 'w') as out_train, \\\n",
    "    open('../../data/medium/habr_holdout.vw', 'w') as out_test:\n",
    "    \n",
    "    lines = train_file.readlines()\n",
    "    lines_amount = len(lines)\n",
    "    split_line = int(train_fraction * lines_amount)\n",
    "    \n",
    "    lines_sequence = np.asarray(range(0, lines_amount))\n",
    "    np.random.seed(17)\n",
    "    np.random.shuffle(lines_sequence)\n",
    "\n",
    "    for idx, index in enumerate(lines_sequence):\n",
    "        if idx < split_line:\n",
    "            out_train.write(lines[index])\n",
    "        else:\n",
    "            out_test.write(lines[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vw -d habr_train.vw -c --passes 3 -k -f habr_model.vw`\n",
    "\n",
    "- c -- Use a cache. The default is <data>.cache\n",
    "- k -- delete cache bafore new learning pass\n",
    "- f -- Final regressor to save (arg is filename)\n",
    "\n",
    "- --ngram arg    Generate N grams. To target a specific namespace write its name as a prefix to arg \n",
    "                         (e.g. --ngram a2 --ngram c3).           \n",
    "- --loss_function squared\n",
    "- --bit_precision  # number of bits in the feature table\n",
    "- --power_t arg (=0.5)         t power value\n",
    "- --bit_precision 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read valid targets \n",
    "import re\n",
    "y = []\n",
    "with open('../../data/medium/habr_holdout.vw') as pred_file:\n",
    "    for line in pred_file:\n",
    "        y.append(float(re.search(\"^\\d\\.?(\\d+)?\", line).group()))\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, hp, tpe, Trials\n",
    "\n",
    "def hyperopt_objective(params):\n",
    "    !vw -d ../../data/medium/habr_train.vw \\\n",
    "    -l {params['l']} \\\n",
    "    --passes {params['passes']} \\\n",
    "    --bit_precision {params['b']} \\\n",
    "    --ngram 2 \\\n",
    "    --normalized \\\n",
    "    --power_t {params['power_t']} \\\n",
    "    --l2 {params['l2']} \\\n",
    "    --quiet \\\n",
    "    -f ../../data/medium/habr_model_search.vw\n",
    "    \n",
    "    !vw -i ../../data/medium/habr_model_search.vw -t \\\n",
    "    -d ../../data/medium/habr_holdout.vw \\\n",
    "    -p ../../data/medium/habr_search_predictions.txt \\\n",
    "    --quiet\n",
    "    \n",
    "    with open('../../data/medium/habr_search_predictions.txt') as pred_file:\n",
    "        prediction = [float(popularity) for popularity in pred_file.readlines()]\n",
    "    score = mean_absolute_error(y, prediction)\n",
    "    return score\n",
    "\n",
    "params_space = {\n",
    "    'l': hp.uniform('l', 0.2, 0.5), # default = 0.5\n",
    "    'power_t': hp.uniform('power_t', 0.3, 0.6), # default = 0.5\n",
    "    'passes': hp.choice('passes', np.arange(1, 3+1, dtype=int)),\n",
    "    'b': hp.choice('b', np.arange(18, 32+1, dtype=int)),\n",
    "    'l2': hp.choice('l2', np.arange(0, 100, 10, dtype=int))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(\n",
    "    hyperopt_objective,\n",
    "    space = params_space,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 100,\n",
    "    trials = trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 7,\n",
       " 'l': 0.48436911072594774,\n",
       " 'l2': 4,\n",
       " 'passes': 1,\n",
       " 'power_t': 0.32076048348406927}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = ../../data/medium/habr_model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.3\n",
      "initial_t = 0\n",
      "power_t = 0.32\n",
      "using no cache\n",
      "Reading datafile = ../../data/medium/habr_train_shuffled.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.058056 0.058056            1            1.0   3.7377   3.4967       91\n",
      "0.098920 0.139785            2            2.0   0.6931   0.3193       31\n",
      "0.188724 0.278529            4            4.0   4.5951   4.4562       55\n",
      "0.180471 0.172217            8            8.0   1.9459   1.9747       35\n",
      "0.298672 0.416874           16           16.0   0.0000   0.1788       45\n",
      "0.492954 0.687236           32           32.0   4.1897   3.3376       45\n",
      "0.345951 0.198947           64           64.0   1.0986   0.7369       37\n",
      "0.367160 0.388370          128          128.0   5.0304   4.4240       49\n",
      "0.297105 0.227050          256          256.0   1.9459   2.1991       29\n",
      "0.313924 0.330742          512          512.0   4.5539   4.2900       45\n",
      "0.288116 0.262307         1024         1024.0   0.0000   0.4870       41\n",
      "0.285399 0.282683         2048         2048.0   6.1985   4.1947       25\n",
      "0.299568 0.313737         4096         4096.0   3.1355   2.2086       37\n",
      "0.295546 0.291524         8192         8192.0   1.7918   1.7600       33\n",
      "0.292407 0.289268        16384        16384.0   1.6094   1.3715       39\n",
      "0.304547 0.316687        32768        32768.0   3.4657   4.0344       45\n",
      "0.317154 0.329762        65536        65536.0   4.0254   3.7288       47\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 84000\n",
      "passes used = 1\n",
      "weighted example sum = 84000.000000\n",
      "weighted label sum = 237362.092683\n",
      "average loss = 0.324817\n",
      "best constant = 2.825739\n",
      "total feature number = 3707698\n"
     ]
    }
   ],
   "source": [
    "# Train Vopal Wabbit\n",
    "!vw -d ../../data/medium/habr_train_shuffled.vw \\\n",
    "-i ../../data/medium/habr_model.vw \\\n",
    "--passes 1 \\\n",
    "--bit_precision 18 \\\n",
    "--ngram 2 \\\n",
    "--power_t 0.32 \\\n",
    "--learning_rate 0.3 \\\n",
    "-f ../../data/medium/habr_model.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and calculate score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = ../../data/medium/test_predictions.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/medium/habr_holdout.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.222426 0.222426            1            1.0   4.4188   4.8905       37\n",
      "1.315150 2.407874            2            2.0   3.3322   1.7805       41\n",
      "0.865549 0.415949            4            4.0   2.5649   3.2470       33\n",
      "1.432184 1.998818            8            8.0   3.4340   1.1685       51\n",
      "1.325224 1.218265           16           16.0   2.3026   1.9629       43\n",
      "1.060018 0.794811           32           32.0   2.8332   3.0493       53\n",
      "0.998244 0.936471           64           64.0   4.1431   4.0730       41\n",
      "1.045088 1.091932          128          128.0   0.0000   0.0000       49\n",
      "1.008048 0.971008          256          256.0   3.5835   2.5482       53\n",
      "1.093236 1.178424          512          512.0   3.9120   2.1859       79\n",
      "1.087637 1.082037         1024         1024.0   2.8904   1.3339       53\n",
      "1.090571 1.093505         2048         2048.0   3.6636   3.9683       47\n",
      "1.118788 1.147005         4096         4096.0   1.7918   3.0885       25\n",
      "1.113994 1.109201         8192         8192.0   0.0000   0.1747       41\n",
      "1.132064 1.150134        16384        16384.0   2.9444   2.6141       57\n",
      "1.127557 1.123050        32768        32768.0   1.3863   1.3236       35\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 36000\n",
      "passes used = 1\n",
      "weighted example sum = 36000.000000\n",
      "weighted label sum = 102013.571981\n",
      "average loss = 1.132668\n",
      "best constant = 2.833710\n",
      "total feature number = 1587344\n"
     ]
    }
   ],
   "source": [
    "!vw -i ../../data/medium/habr_model.vw -t -d ../../data/medium/habr_holdout.vw \\\n",
    "-p ../../data/medium/test_predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.418841,  3.332205,  2.995732, ...,  4.127134,  3.091042,\n",
       "        3.295837])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read valid targets \n",
    "y.shape\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read predictions\n",
    "predicted = pd.read_table('../../data/medium/test_predictions.txt', header=-1, names='h')\n",
    "predicted = np.asarray(predicted['h'])\n",
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83239817030555552"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### History\n",
    "1. MAE: 0.97,  hour, month, no train shuffle\n",
    "2. MAE: 0.843,  hour_sin, hour_cos, month_sin, month_cos, train shuffle, \n",
    "--cache -k \\\n",
    "--passes 3 \\\n",
    "--bit_precision 26 \\\n",
    "--ngram 2 \\\n",
    "--normalized \\\n",
    "--power_t 0.3 \\\n",
    "--learning_rate 0.1 \\\n",
    "3. MAE: 0.854, +trend_month, Hyperopt {'b': 20.72730122196693,\n",
    " 'l': 0.36358056461078,\n",
    " 'passes': 1.7400215119677327,\n",
    " 'power_t': 0.4893971209575465}\n",
    "4. MAE: 1.65 :(  Hyperopt + L2\n",
    "5. MAE: 0.8037"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle train\n",
    "with open('../../data/medium/habr_train.vw') as train_file, \\\n",
    "    open('../../data/medium/habr_train_shuffled.vw', 'w') as out_train:\n",
    "    \n",
    "    lines = train_file.readlines()\n",
    "    lines_amount = len(lines)\n",
    "    lines_sequence = np.asarray(range(0, lines_amount))\n",
    "    np.random.seed(17)\n",
    "    np.random.shuffle(lines_sequence)\n",
    "\n",
    "    for idx, index in enumerate(lines_sequence):\n",
    "        out_train.write(lines[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = ../../data/medium/habr_model_full.vw\n",
      "Num weight bits = 26\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.3\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = ../../data/medium/habr_train_full_shuffled.vw.cache\n",
      "Reading datafile = ../../data/medium/habr_train_full_shuffled.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "14.490676 14.490676            1            1.0   3.8067   0.0000       33\n",
      "7.573176 0.655676            2            2.0   0.0000   0.8097       23\n",
      "4.661352 1.749528            4            4.0   0.6931   0.4766       43\n",
      "6.190978 7.720605            8            8.0   4.9488   0.5731       33\n",
      "5.931946 5.672914           16           16.0   4.0943   2.8145       57\n",
      "4.504505 3.077063           32           32.0   5.0626   3.3337       59\n",
      "3.836956 3.169407           64           64.0   3.9890   2.1413       55\n",
      "2.921809 2.006662          128          128.0   1.9459   2.6901       43\n",
      "2.423077 1.924346          256          256.0   0.0000   1.0991       25\n",
      "2.128341 1.833605          512          512.0   1.0986   3.3310       47\n",
      "2.119097 2.109853         1024         1024.0   1.0986   1.6793       27\n",
      "1.928359 1.737622         2048         2048.0   1.9459   3.0949       57\n",
      "1.782006 1.635652         4096         4096.0   0.0000   1.3770       45\n",
      "1.702573 1.623140         8192         8192.0   2.6391   3.0088       43\n",
      "1.590589 1.478605        16384        16384.0   0.6931   3.0677       27\n",
      "1.509316 1.428043        32768        32768.0   3.4012   3.1211       35\n",
      "1.401046 1.292775        65536        65536.0   2.4849   3.2581       41\n",
      "1.328072 1.328072       131072       131072.0   0.0000   0.9823       25 h\n",
      "1.248948 1.169830       262144       262144.0   3.1781   2.9011       47 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 108000\n",
      "passes used = 3\n",
      "weighted example sum = 324000.000000\n",
      "weighted label sum = 916705.549641\n",
      "average loss = 1.151312 h\n",
      "best constant = 2.829338\n",
      "total feature number = 13653684\n"
     ]
    }
   ],
   "source": [
    "# Train on full set\n",
    "!vw -d ../../data/medium/habr_train_full_shuffled.vw \\\n",
    "--cache -k \\\n",
    "--passes 3 \\\n",
    "--bit_precision 26 \\\n",
    "--ngram 2 \\\n",
    "--normalized \\\n",
    "--power_t 0.3 \\\n",
    "--learning_rate 0.1 \\\n",
    "-f ../../data/medium/habr_model_full.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = ../../data/medium/submission_predictions.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/medium/habr_test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.007794 0.007794            1            1.0   1.0000   1.0883       23\n",
      "0.315328 0.622863            2            2.0   1.0000   1.7892       43\n",
      "0.928896 1.542463            4            4.0   1.0000   2.7453       33\n",
      "2.449759 3.970623            8            8.0   1.0000   2.8498       31\n",
      "2.541882 2.634004           16           16.0   1.0000   0.0000       29\n",
      "2.469460 2.397039           32           32.0   1.0000   2.9229       33\n",
      "2.179791 1.890121           64           64.0   1.0000   0.6755       37\n",
      "2.176768 2.173745          128          128.0   1.0000   2.5735       37\n",
      "1.986002 1.795237          256          256.0   1.0000   4.0396       41\n",
      "2.252425 2.518848          512          512.0   1.0000   1.1753       29\n",
      "2.388565 2.524705         1024         1024.0   1.0000   2.9127       23\n",
      "2.443442 2.498319         2048         2048.0   1.0000   3.7182       37\n",
      "2.447268 2.451093         4096         4096.0   1.0000   1.0145       31\n",
      "2.530047 2.612827         8192         8192.0   1.0000   2.5197       39\n",
      "2.915834 3.301621        16384        16384.0   1.0000   1.6293       43\n",
      "3.488011 4.060188        32768        32768.0   1.0000   4.0151       69\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 52913\n",
      "passes used = 1\n",
      "weighted example sum = 52913.000000\n",
      "weighted label sum = 52913.000000\n",
      "average loss = 4.267157\n",
      "best constant = 1.000000\n",
      "best constant's loss = 0.000000\n",
      "total feature number = 2134589\n"
     ]
    }
   ],
   "source": [
    "!vw -i ../../data/medium/habr_model.vw -t -d ../../data/medium/habr_test.vw \\\n",
    "-p ../../data/medium/submission_predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv('../../data/medium/sample_submission.csv', \n",
    "                         index_col='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/87455/</th>\n",
       "      <td>11.620054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/87452/</th>\n",
       "      <td>4.822528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/87459/</th>\n",
       "      <td>0.921104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habrahabr.ru/post/87461/</th>\n",
       "      <td>1.632126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habrahabr.ru/post/5754/</th>\n",
       "      <td>1.952122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     target\n",
       "url                                        \n",
       "https://geektimes.ru/post/87455/  11.620054\n",
       "https://geektimes.ru/post/87452/   4.822528\n",
       "https://geektimes.ru/post/87459/   0.921104\n",
       "https://habrahabr.ru/post/87461/   1.632126\n",
       "https://habrahabr.ru/post/5754/    1.952122"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/87455/</th>\n",
       "      <td>11.620054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/87452/</th>\n",
       "      <td>4.822528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/87459/</th>\n",
       "      <td>0.921104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habrahabr.ru/post/87461/</th>\n",
       "      <td>1.632126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://habrahabr.ru/post/5754/</th>\n",
       "      <td>1.952122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     target\n",
       "url                                        \n",
       "https://geektimes.ru/post/87455/  11.620054\n",
       "https://geektimes.ru/post/87452/   4.822528\n",
       "https://geektimes.ru/post/87459/   0.921104\n",
       "https://habrahabr.ru/post/87461/   1.632126\n",
       "https://habrahabr.ru/post/5754/    1.952122"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_submission = sample_sub.copy()\n",
    "your_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52913 52913\n"
     ]
    }
   ],
   "source": [
    "predicted = pd.read_table('../../data/medium/submission_predictions.txt', header=-1, names='h')\n",
    "predicted = np.asarray(predicted['h'])\n",
    "print(predicted.shape[0], your_submission.index.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "your_submission['target'] = predicted\n",
    "your_submission.to_csv('../../data/medium/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для получения баллов в #mlcourse_open команда (из 1 человека) должна называться в точном соответствии с тем, как оно записано в рейтинге."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
